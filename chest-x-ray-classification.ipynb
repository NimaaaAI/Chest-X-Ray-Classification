{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f1c948",
   "metadata": {
    "papermill": {
     "duration": 0.003586,
     "end_time": "2026-02-10T09:22:47.139615",
     "exception": false,
     "start_time": "2026-02-10T09:22:47.136029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Overview\n",
    "\n",
    "This project focuses on building a **binary classification model** to detect **Pneumonia vs Normal** from chest X-ray images.  \n",
    "\n",
    "We use the **Chest X-Ray and OCT Medical Image Dataset** and implement the following workflow:\n",
    "\n",
    "1. **Data Exploration:**  \n",
    "   - Inspect the dataset structure, count images per class, and visualize samples.  \n",
    "   - Check class distribution and prepare for training/validation/test splits.  \n",
    "\n",
    "2. **Data Preparation:**  \n",
    "   - Apply **data augmentation** on the training set to improve model robustness.  \n",
    "   - Split the original training set into **training** (80%) and **validation** (20%) sets.  \n",
    "   - Normalize images based on ImageNet statistics and prepare PyTorch `DataLoaders`.  \n",
    "\n",
    "3. **Model Setup:**  \n",
    "   - Load a pre-trained **DenseNet121** model.  \n",
    "   - Fine-tune the last two dense blocks and replace the classifier for binary output.  \n",
    "   - Use **BCEWithLogitsLoss**, Adam optimizer, and a learning rate scheduler.  \n",
    "\n",
    "4. **Training & Validation:**  \n",
    "   - Train the model while monitoring validation loss and accuracy.  \n",
    "   - Implement **early stopping** to avoid overfitting.  \n",
    "   - Save the best model based on validation performance.  \n",
    "\n",
    "5. **Testing & Evaluation:**  \n",
    "   - Evaluate the best model on the test set.  \n",
    "   - Compute accuracy, confusion matrix, and a full classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5eb4ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:22:47.146347Z",
     "iopub.status.busy": "2026-02-10T09:22:47.146066Z",
     "iopub.status.idle": "2026-02-10T09:22:59.720312Z",
     "shell.execute_reply": "2026-02-10T09:22:59.719517Z"
    },
    "papermill": {
     "duration": 12.579511,
     "end_time": "2026-02-10T09:22:59.721930",
     "exception": false,
     "start_time": "2026-02-10T09:22:47.142419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import DenseNet121_Weights\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a699749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:22:59.728642Z",
     "iopub.status.busy": "2026-02-10T09:22:59.728251Z",
     "iopub.status.idle": "2026-02-10T09:22:59.870661Z",
     "shell.execute_reply": "2026-02-10T09:22:59.869897Z"
    },
    "papermill": {
     "duration": 0.147372,
     "end_time": "2026-02-10T09:22:59.872088",
     "exception": false,
     "start_time": "2026-02-10T09:22:59.724716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/chest-x-ray-and-oct-medical-image-dataset\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"gallo33henrique/chest-x-ray-and-oct-medical-image-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15823e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:22:59.878538Z",
     "iopub.status.busy": "2026-02-10T09:22:59.878317Z",
     "iopub.status.idle": "2026-02-10T09:23:12.303135Z",
     "shell.execute_reply": "2026-02-10T09:23:12.302308Z"
    },
    "papermill": {
     "duration": 12.429867,
     "end_time": "2026-02-10T09:23:12.304626",
     "exception": false,
     "start_time": "2026-02-10T09:22:59.874759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory structure:\n",
      "\n",
      "â”œâ”€â”€ chest-x-ray-and-oct-medical-image-dataset/\n",
      "â”‚   â”œâ”€â”€ data/\n",
      "â”‚   â”‚   â”œâ”€â”€ test/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ PNEUMONIA/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person1676_virus_2892.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person1650_virus_2852.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person22_virus_55.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person122_bacteria_582.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person85_bacteria_417.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ NORMAL/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-0336-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     IM-0101-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-0337-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-0198-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     IM-0013-0001.jpeg\n",
      "â”‚   â”‚   â”œâ”€â”€ train/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ PNEUMONIA/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person1180_virus_2010.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person1230_virus_2081.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person1513_virus_2632.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person124_virus_238.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     person746_virus_1369.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€ NORMAL/\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-0771-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-1294-0001-0002.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     IM-0675-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     NORMAL2-IM-1169-0001.jpeg\n",
      "â”‚   â”‚   â”‚   â”œâ”€â”€     IM-0421-0001.jpeg\n"
     ]
    }
   ],
   "source": [
    "base_path = path\n",
    "\n",
    "def print_dir_tree(start_path, max_depth=3):\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        depth = root.replace(start_path, \"\").count(os.sep)\n",
    "        if depth > max_depth:\n",
    "            continue\n",
    "        indent = \"â”‚   \" * depth + \"â”œâ”€â”€ \"\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        for f in files[:5]:\n",
    "            print(f\"{indent}    {f}\")\n",
    "\n",
    "print(\"Dataset directory structure:\\n\")\n",
    "print_dir_tree(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7210bd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:12.312063Z",
     "iopub.status.busy": "2026-02-10T09:23:12.311477Z",
     "iopub.status.idle": "2026-02-10T09:23:12.322834Z",
     "shell.execute_reply": "2026-02-10T09:23:12.322057Z"
    },
    "papermill": {
     "duration": 0.016557,
     "end_time": "2026-02-10T09:23:12.324325",
     "exception": false,
     "start_time": "2026-02-10T09:23:12.307768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN SET\n",
      "--------------------\n",
      "PNEUMONIA   : 3883\n",
      "NORMAL      : 1349\n",
      "Total images: 5232\n",
      "\n",
      "TEST SET\n",
      "--------------------\n",
      "PNEUMONIA   : 390\n",
      "NORMAL      : 234\n",
      "Total images: 624\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(base_path, \"data\")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "class_counts = defaultdict(dict)\n",
    "\n",
    "for split in splits:\n",
    "    split_path = os.path.join(data_path, split)\n",
    "    for cls in os.listdir(split_path):\n",
    "        cls_path = os.path.join(split_path, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            num_images = len([\n",
    "                f for f in os.listdir(cls_path)\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "            ])\n",
    "            class_counts[split][cls] = num_images\n",
    "\n",
    "for split in class_counts:\n",
    "    print(f\"\\n{split.upper()} SET\")\n",
    "    print(\"-\" * 20)\n",
    "    for cls, count in class_counts[split].items():\n",
    "        print(f\"{cls:<12}: {count}\")\n",
    "    print(f\"Total images: {sum(class_counts[split].values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51e0dd",
   "metadata": {
    "papermill": {
     "duration": 0.002902,
     "end_time": "2026-02-10T09:23:12.330137",
     "exception": false,
     "start_time": "2026-02-10T09:23:12.327235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We split the original training set into **training** and **validation** subsets (80/20) because the test set should only be used for the final evaluation.  \n",
    "\n",
    "- **Training set:** used to train the model.  \n",
    "- **Validation set:** used to monitor performance and tune the model during training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9104c08d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:12.336746Z",
     "iopub.status.busy": "2026-02-10T09:23:12.336521Z",
     "iopub.status.idle": "2026-02-10T09:23:13.401143Z",
     "shell.execute_reply": "2026-02-10T09:23:13.400332Z"
    },
    "papermill": {
     "duration": 1.069633,
     "end_time": "2026-02-10T09:23:13.402606",
     "exception": false,
     "start_time": "2026-02-10T09:23:12.332973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4185\n",
      "Validation samples: 1047\n"
     ]
    }
   ],
   "source": [
    "original_train_path = os.path.join(data_path, \"train\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=original_train_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a807b5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:13.410318Z",
     "iopub.status.busy": "2026-02-10T09:23:13.409675Z",
     "iopub.status.idle": "2026-02-10T09:23:13.419242Z",
     "shell.execute_reply": "2026-02-10T09:23:13.418491Z"
    },
    "papermill": {
     "duration": 0.014918,
     "end_time": "2026-02-10T09:23:13.420711",
     "exception": false,
     "start_time": "2026-02-10T09:23:13.405793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verification (In-Memory Splits):\n",
      "\n",
      "TRAIN SET\n",
      "-------------------------\n",
      "NORMAL      : 1079\n",
      "PNEUMONIA   : 3106\n",
      "Total images: 4185\n",
      "\n",
      "VAL SET\n",
      "-------------------------\n",
      "NORMAL      : 270\n",
      "PNEUMONIA   : 777\n",
      "Total images: 1047\n",
      "\n",
      "TEST SET\n",
      "-------------------------\n",
      "PNEUMONIA   : 390\n",
      "NORMAL      : 234\n",
      "Total images: 624\n",
      "\n",
      "Verification complete âœ…\n"
     ]
    }
   ],
   "source": [
    "dataset_splits = {\n",
    "    \"TRAIN\": train_dataset,\n",
    "    \"VAL\": val_dataset\n",
    "}\n",
    "\n",
    "print(\"Dataset verification (In-Memory Splits):\\n\")\n",
    "\n",
    "for name, subset in dataset_splits.items():\n",
    "    print(f\"{name} SET\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "\n",
    "    class_names = full_dataset.classes\n",
    "    indices = subset.indices\n",
    "    labels = [full_dataset.targets[i] for i in indices]\n",
    "    \n",
    "    total = 0\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        count = labels.count(i)\n",
    "        print(f\"{class_name:<12}: {count}\")\n",
    "        total += count\n",
    "    \n",
    "    print(f\"Total images: {total}\\n\")\n",
    "\n",
    "test_path = os.path.join(data_path, \"test\")\n",
    "print(\"TEST SET\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "if os.path.exists(test_path):\n",
    "    test_total = 0\n",
    "    for cls in os.listdir(test_path):\n",
    "        cls_path = os.path.join(test_path, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            num_images = len([f for f in os.listdir(cls_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
    "            print(f\"{cls:<12}: {num_images}\")\n",
    "            test_total += num_images\n",
    "    print(f\"Total images: {test_total}\\n\")\n",
    "else:\n",
    "    print(\"âŒ Test folder not found!\\n\")\n",
    "\n",
    "print(\"Verification complete âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e995e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:13.427750Z",
     "iopub.status.busy": "2026-02-10T09:23:13.427536Z",
     "iopub.status.idle": "2026-02-10T09:23:13.721132Z",
     "shell.execute_reply": "2026-02-10T09:23:13.720504Z"
    },
    "papermill": {
     "duration": 0.298986,
     "end_time": "2026-02-10T09:23:13.722758",
     "exception": false,
     "start_time": "2026-02-10T09:23:13.423772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121\n",
    "model = densenet121()\n",
    "#print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb8710",
   "metadata": {
    "papermill": {
     "duration": 0.003007,
     "end_time": "2026-02-10T09:23:13.729046",
     "exception": false,
     "start_time": "2026-02-10T09:23:13.726039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prepares the dataset and dataloaders for training, validation, and testing:**\n",
    "\n",
    "1. **Settings:** defines image size, batch size, number of workers, and random seed for reproducibility.  \n",
    "2. **Transforms:**  \n",
    "   - `train_transforms` applies data augmentation (random crop, flip, rotation, color jitter) to make the model more robust.  \n",
    "   - `val_test_transforms` resizes and normalizes images without augmentation for validation and testing.  \n",
    "3. **Dataset split:** the original training data is split into **train** (80%) and **validation** (20%) subsets using a fixed random seed.  \n",
    "4. **DataLoaders:** wrap the datasets for efficient batch loading during training and evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce78942a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:13.736190Z",
     "iopub.status.busy": "2026-02-10T09:23:13.735922Z",
     "iopub.status.idle": "2026-02-10T09:23:14.360306Z",
     "shell.execute_reply": "2026-02-10T09:23:14.359480Z"
    },
    "papermill": {
     "duration": 0.629889,
     "end_time": "2026-02-10T09:23:14.361849",
     "exception": false,
     "start_time": "2026-02-10T09:23:13.731960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NORMAL', 'PNEUMONIA']\n",
      "Train samples: 4186\n",
      "Val samples:   1046\n",
      "Test samples:  624\n",
      "DataLoaders ready âœ…\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2  \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "\n",
    "full_train_data = datasets.ImageFolder(os.path.join(data_path, \"train\"), transform=train_transforms)\n",
    "full_val_data   = datasets.ImageFolder(os.path.join(data_path, \"train\"), transform=val_test_transforms)\n",
    "\n",
    "\n",
    "num_train = len(full_train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.2 * num_train)) \n",
    "\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_train_data, train_idx)\n",
    "val_dataset   = torch.utils.data.Subset(full_val_data, val_idx)\n",
    "\n",
    "\n",
    "test_dataset  = datasets.ImageFolder(os.path.join(data_path, \"test\"), transform=val_test_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "class_names = full_train_data.classes\n",
    "print(\"Classes:\", class_names)\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples:   {len(val_dataset)}\")\n",
    "print(f\"Test samples:  {len(test_dataset)}\")\n",
    "print(\"DataLoaders ready âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6e81f",
   "metadata": {
    "papermill": {
     "duration": 0.003069,
     "end_time": "2026-02-10T09:23:14.368204",
     "exception": false,
     "start_time": "2026-02-10T09:23:14.365135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Set up the model, loss, and optimizer for training:**\n",
    "\n",
    "1. **Device:** uses GPU if available for faster training.  \n",
    "2. **Model:** loads a pre-trained **DenseNet121**.  \n",
    "   - Only the last two dense blocks (`denseblock3` and `denseblock4`) are fine-tuned; earlier layers are frozen.  \n",
    "   - The classifier is replaced with a **dropout + linear layer** for binary classification.  \n",
    "3. **Loss & Optimizer:** uses `BCEWithLogitsLoss` and Adam optimizer (only trainable parameters).  \n",
    "4. **Scheduler:** reduces learning rate if validation loss plateaus.  \n",
    "\n",
    "The model is then moved to the selected device and ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f64530d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:14.375347Z",
     "iopub.status.busy": "2026-02-10T09:23:14.374867Z",
     "iopub.status.idle": "2026-02-10T09:23:15.431757Z",
     "shell.execute_reply": "2026-02-10T09:23:15.430965Z"
    },
    "papermill": {
     "duration": 1.062196,
     "end_time": "2026-02-10T09:23:15.433318",
     "exception": false,
     "start_time": "2026-02-10T09:23:14.371122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 165MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121 model ready âœ…\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = models.densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"denseblock3\" in name or \"denseblock4\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(num_features, 1)  \n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.3, patience=3, min_lr=1e-7\n",
    ")\n",
    "\n",
    "print(\"DenseNet121 model ready âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5ab1e",
   "metadata": {
    "papermill": {
     "duration": 0.003308,
     "end_time": "2026-02-10T09:23:15.440148",
     "exception": false,
     "start_time": "2026-02-10T09:23:15.436840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Training & Validation functions:**  \n",
    "   - `train_one_epoch` runs a full pass over the training data, computing loss and accuracy, and updating model weights.  \n",
    "   - `validate` evaluates the model on the validation set without updating weights.  \n",
    "\n",
    "\n",
    "2. **Training loop:**  \n",
    "   - Runs for a maximum of `MAX_EPOCHS` epochs.  \n",
    "   - After each epoch, the validation loss is monitored.  \n",
    "   - Learning rate is reduced if validation loss plateaus.  \n",
    "   - The model is saved whenever validation loss improves.  \n",
    "\n",
    "\n",
    "3. **Early stopping:** stops training if validation loss does not improve for `PATIENCE` consecutive epochs.  \n",
    "\n",
    "Finally, the best model (with lowest validation loss) is loaded for further evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91385418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:23:15.447792Z",
     "iopub.status.busy": "2026-02-10T09:23:15.447547Z",
     "iopub.status.idle": "2026-02-10T09:35:09.506899Z",
     "shell.execute_reply": "2026-02-10T09:35:09.505912Z"
    },
    "papermill": {
     "duration": 714.065161,
     "end_time": "2026-02-10T09:35:09.508577",
     "exception": false,
     "start_time": "2026-02-10T09:23:15.443416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1908 | Train Acc: 0.9271\n",
      "Val   Loss: 0.0714 | Val   Acc: 0.9771\n",
      "âœ… Validation loss improved â€” saving model\n",
      "\n",
      "Epoch 2/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0945 | Train Acc: 0.9694\n",
      "Val   Loss: 0.0475 | Val   Acc: 0.9837\n",
      "âœ… Validation loss improved â€” saving model\n",
      "\n",
      "Epoch 3/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0827 | Train Acc: 0.9687\n",
      "Val   Loss: 0.0530 | Val   Acc: 0.9790\n",
      "âš ï¸ No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0636 | Train Acc: 0.9775\n",
      "Val   Loss: 0.0427 | Val   Acc: 0.9876\n",
      "âœ… Validation loss improved â€” saving model\n",
      "\n",
      "Epoch 5/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0600 | Train Acc: 0.9787\n",
      "Val   Loss: 0.0440 | Val   Acc: 0.9847\n",
      "âš ï¸ No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 6/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0470 | Train Acc: 0.9823\n",
      "Val   Loss: 0.0721 | Val   Acc: 0.9723\n",
      "âš ï¸ No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 7/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0358 | Train Acc: 0.9876\n",
      "Val   Loss: 0.0375 | Val   Acc: 0.9904\n",
      "âœ… Validation loss improved â€” saving model\n",
      "\n",
      "Epoch 8/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0304 | Train Acc: 0.9907\n",
      "Val   Loss: 0.0452 | Val   Acc: 0.9857\n",
      "âš ï¸ No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 9/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0249 | Train Acc: 0.9912\n",
      "Val   Loss: 0.0463 | Val   Acc: 0.9866\n",
      "âš ï¸ No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 10/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0190 | Train Acc: 0.9945\n",
      "Val   Loss: 0.0431 | Val   Acc: 0.9885\n",
      "âš ï¸ No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 11/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0173 | Train Acc: 0.9955\n",
      "Val   Loss: 0.0401 | Val   Acc: 0.9895\n",
      "âš ï¸ No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 12/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0166 | Train Acc: 0.9945\n",
      "Val   Loss: 0.0403 | Val   Acc: 0.9895\n",
      "âš ï¸ No improvement for 5 epoch(s)\n",
      "\n",
      "â¹ï¸ Early stopping triggered\n",
      "\n",
      "Best model loaded âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "MAX_EPOCHS = 25\n",
    "PATIENCE = 5\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{MAX_EPOCHS}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"ðŸ”» LR reduced: {old_lr:.2e} -> {new_lr:.2e}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, \"/kaggle/working/best_model.pth\")\n",
    "        epochs_no_improve = 0\n",
    "        print(\"âœ… Validation loss improved â€” saving model\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"âš ï¸ No improvement for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(\"\\nâ¹ï¸ Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), \"/kaggle/working/best_model_final.pth\")\n",
    "print(\"\\nBest model loaded âœ…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75476391",
   "metadata": {
    "papermill": {
     "duration": 0.073666,
     "end_time": "2026-02-10T09:35:09.657620",
     "exception": false,
     "start_time": "2026-02-10T09:35:09.583954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Evaluate the **trained model** on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab43416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T09:35:09.879595Z",
     "iopub.status.busy": "2026-02-10T09:35:09.879302Z",
     "iopub.status.idle": "2026-02-10T09:35:18.364679Z",
     "shell.execute_reply": "2026-02-10T09:35:18.363505Z"
    },
    "papermill": {
     "duration": 8.562365,
     "end_time": "2026-02-10T09:35:18.367366",
     "exception": false,
     "start_time": "2026-02-10T09:35:09.805001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9263\n",
      "Confusion Matrix:\n",
      " [[189  45]\n",
      " [  1 389]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.99      0.81      0.89       234\n",
      "   PNEUMONIA       0.90      1.00      0.94       390\n",
      "\n",
      "    accuracy                           0.93       624\n",
      "   macro avg       0.95      0.90      0.92       624\n",
      "weighted avg       0.93      0.93      0.92       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "test_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9153593,
     "sourceId": 14336835,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 816.633245,
   "end_time": "2026-02-10T09:36:21.211696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-10T09:22:44.578451",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
